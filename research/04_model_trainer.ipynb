{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Anaconda Projects\\\\end to end wine quality fifth\\\\end-to-end-wine-quality-fifth\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Anaconda Projects/end to end wine quality fifth/end-to-end-wine-quality-fifth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Anaconda Projects\\\\end to end wine quality fifth\\\\end-to-end-wine-quality-fifth'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    # alpha: float\n",
    "    # l1_ration: float\n",
    "    target_column: str\n",
    "    model_to_loop: str\n",
    "    model_params: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject import *\n",
    "from box import ConfigBox\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def evaluate_models(x_train, x_test, y_train, y_test, models: ConfigBox, params) -> dict:\n",
    "    try:\n",
    "        report = {}\n",
    "        logger.info(f\"Entered to model evaluation list\")\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = eval(list(models.values())[i])\n",
    "            \n",
    "            param = params[list(models.keys())[i]]\n",
    "\n",
    "            rs = RandomizedSearchCV(model, param)\n",
    "\n",
    "            rs.fit(x_train, y_train)\n",
    "\n",
    "            # model.fit(x_train, y_train)\n",
    "\n",
    "            model.set_params(**rs.best_params_)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            test_model_r2_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_r2_score\n",
    "\n",
    "        return report\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath = (CONFIG_FILE_PATH),\n",
    "                 params_filepath = (PARAMS_FILE_PATH),\n",
    "                 schema_filepath = (SCHEME_FILE_PATH),\n",
    "                 model_p_filepath = (MODEL_P_FILE_PATH)):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        self.model_p = read_yaml(model_p_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "\n",
    "        config = self.config.model_trainer\n",
    "        # params = self.params.ElasticNet\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "        model = self.params.models\n",
    "        model_p = self.model_p.params\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            # alpha=params.alpha,\n",
    "            # l1_ration=params.l1_ratio,\n",
    "            target_column=schema.name,\n",
    "            model_to_loop = model,\n",
    "            model_params = model_p\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-23 15:24:27,424: INFO: utils: NumExpr defaulting to 4 threads.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import joblib\n",
    "# from mlProject.utils.common import evaluate_models\n",
    "from mlProject import *\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config  = config\n",
    "\n",
    "    def train(self):\n",
    "        train_data = pd.read_csv(self.config.train_data_path)\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x = train_data.drop([self.config.target_column], axis=1)\n",
    "        train_y = train_data[self.config.target_column]\n",
    "\n",
    "        test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "        test_y = test_data[self.config.target_column]\n",
    "        models = self.config.model_to_loop\n",
    "        model_p = self.config.model_params\n",
    "        logger.info(f\"Models parameters are ready to print\")\n",
    "        print(model_p)\n",
    "        print(model_p.keys())\n",
    "        # print((model_p.values()).keys())\n",
    "        print(model_p.values())\n",
    "\n",
    "        model_report:dict = evaluate_models(x_train=train_x, y_train=train_y, x_test=test_x, y_test=test_y, models=models, params=model_p)\n",
    "\n",
    "        print(model_report)\n",
    "        \n",
    "        best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "        best_model_name = list(model_report.keys())[\n",
    "            list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "        best_model = models[best_model_name]\n",
    "\n",
    "        logging.info(f\"Best model is {best_model_name} and its r2 score is {best_model_score}\")\n",
    "\n",
    "        # lr = ElasticNet(alpha=self.config.alpha, l1_ratio=self.config.l1_ration, random_state=42)\n",
    "\n",
    "        # lr.fit(train_x, train_y)\n",
    "\n",
    "        joblib.dump(best_model, os.path.join(self.config.root_dir, self.config.model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-23 15:24:29,076: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-23 15:24:29,076: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-23 15:24:29,092: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-01-23 15:24:29,113: INFO: common: yaml file: model_params.yaml loaded successfully]\n",
      "[2024-01-23 15:24:29,117: INFO: common: Created directory at artifacts]\n",
      "[2024-01-23 15:24:29,117: INFO: common: Created directory at artifacts/model_trainer]\n",
      "[2024-01-23 15:24:29,153: INFO: 3570552939: Models parameters are ready to print]\n",
      "{'Linear Regression': {'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [-1, 1, 'None']}, 'K-Neighbors Regressor': {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30], 'p': [1, 2], 'metric': ['minkowski', 'euclidean', 'manhattan']}, 'Decision Tree': {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}, 'Random Forest Regressor': {'n_estimators': [8, 16, 32, 64, 128, 256]}, 'XGBRegressor': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'CatBoosting Regressor': {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}, 'AdaBoost Regressor': {'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}, 'Gradient Boosting': {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]}}\n",
      "dict_keys(['Linear Regression', 'K-Neighbors Regressor', 'Decision Tree', 'Random Forest Regressor', 'XGBRegressor', 'CatBoosting Regressor', 'AdaBoost Regressor', 'Gradient Boosting'])\n",
      "dict_values([ConfigBox({'fit_intercept': [True, False], 'copy_X': [True, False], 'n_jobs': [-1, 1, 'None']}), ConfigBox({'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [10, 20, 30], 'p': [1, 2], 'metric': ['minkowski', 'euclidean', 'manhattan']}), ConfigBox({'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}), ConfigBox({'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}), ConfigBox({'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]})])\n",
      "[2024-01-23 15:24:29,157: INFO: 3325975768: Entered to model evaluation list]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_jobs' parameter of LinearRegression must be None or an instance of 'int'. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.32249015        nan 0.32249015        nan 0.32249015\n",
      " 0.32173891 0.32249015 0.32173891 0.32173891]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear Regression': 0.40194597307221736, 'K-Neighbors Regressor': 0.36538284164001866, 'Decision Tree': -0.12852851955348998, 'Random Forest Regressor': 0.5254534341423961, 'XGBRegressor': 0.4703834378309344, 'CatBoosting Regressor': 0.5251365679710166, 'AdaBoost Regressor': 0.36314935232456236, 'Gradient Boosting': 0.4915575891260189}\n",
      "[2024-01-23 15:27:21,152: INFO: 3570552939: Best model is Random Forest Regressor and its r2 score is 0.5254534341423961]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
